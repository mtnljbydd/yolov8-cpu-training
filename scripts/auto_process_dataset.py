import os
import shutil
import random
import yaml
import json
import cv2
from tqdm import tqdm

# åŠ è½½é…ç½®
def load_total_config(config_path="./config/total_config.yaml"):
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # 1. è§£æè·¯å¾„ï¼ˆä»…è¯»å–æŒ‡å®šçš„å•ä¸ªç›®å½•ï¼‰
    root_path = os.path.abspath(config['paths']['root_path'])
    target_scene_dir = os.path.abspath(config['paths']['target_scene_dir'])  # å•ä¸ªç›®æ ‡ç›®å½•
    output_root = os.path.abspath(config['paths']['output_root'])
    
    # 2. è§£æç±»åˆ«æ˜ å°„
    class_dict = config['dataset']['class_dict']
    cn2en = class_dict
    en2cid = {en_name: idx for idx, en_name in enumerate(class_dict.values())}
    
    return {
        "target_scene_dir": target_scene_dir,  # ä»…å¤„ç†è¿™ä¸ªç›®å½•
        "output_root": output_root,
        "train_path": os.path.join(output_root, 'train'),
        "val_path": os.path.join(output_root, 'val'),
        "cn2en": cn2en,
        "en2cid": en2cid,
        "class_num": len(class_dict),
        "train_ratio": config['dataset']['train_ratio'],
        "random_seed": config['dataset']['random_seed'],
        "img_formats": config['dataset']['img_formats'],
        "delete_temp": config['dataset']['delete_temp_files'],
        "config_path": config_path
    }

# æ‰«ææŒ‡å®šçš„å•ä¸ªç›®å½•ï¼Œæ”¶é›†<å›¾åƒ, JSON>é…å¯¹
def scan_target_dir(config):
    file_pairs = []
    scene_path = config['target_scene_dir']
    
    # æ£€æŸ¥æŒ‡å®šç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(scene_path):
        print(f"âŒ é”™è¯¯ï¼šæŒ‡å®šçš„ç›®å½•ä¸å­˜åœ¨ â†’ {scene_path}")
        return []
    
    print(f"âœ… å¼€å§‹å¤„ç†æŒ‡å®šç›®å½•ï¼š{scene_path}")
    
    # ä»…éå†è¯¥ç›®å½•ä¸‹çš„å›¾åƒæ–‡ä»¶
    img_files = [f for f in os.listdir(scene_path) 
                 if any(f.lower().endswith(fmt) for fmt in config['img_formats'])]
    
    if not img_files:
        print(f"âŒ {scene_path} ä¸‹æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶ï¼ˆæ”¯æŒæ ¼å¼ï¼š{config['img_formats']}ï¼‰")
        return []
    
    # åŒ¹é…å›¾åƒå’Œå¯¹åº”çš„JSONæ ‡æ³¨
    for img_file in img_files:
        img_path = os.path.join(scene_path, img_file)
        json_name = os.path.splitext(img_file)[0] + '.json'
        json_path = os.path.join(scene_path, json_name)
        
        if os.path.exists(json_path):
            file_pairs.append((img_path, json_path))
        else:
            print(f"âš ï¸ {img_path} æ— å¯¹åº”JSONæ ‡æ³¨ï¼Œè·³è¿‡")
    
    if not file_pairs:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•<å›¾åƒ+JSON>é…å¯¹æ–‡ä»¶")
        return []
    
    print(f"âœ… å…±æ‰¾åˆ° {len(file_pairs)} ç»„æœ‰æ•ˆæ•°æ®")
    return file_pairs

# LabelMe JSONè½¬YOLO TXTæ ‡ç­¾ï¼ˆé€»è¾‘ä¸å˜ï¼‰
def json2yolo(img_path, json_path, save_label_path, config):
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        img = cv2.imread(img_path)
        if img is None:
            print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ {img_path}ï¼Œè·³è¿‡")
            return False
        img_h, img_w = img.shape[:2]
        
        txt_lines = []
        for shape in data['shapes']:
            original_cn_label = shape['label'].strip()
            
            if original_cn_label not in config['cn2en']:
                print(f"âš ï¸ {json_path} ä¸­æœªçŸ¥ç±»åˆ«ï¼š{original_cn_label}ï¼Œè·³è¿‡è¯¥æ ‡æ³¨")
                continue
            en_label = config['cn2en'][original_cn_label]
            cid = config['en2cid'].get(en_label, -1)
            if cid == -1:
                print(f"âš ï¸ {json_path} ä¸­ {original_cn_label} â†’ {en_label} æ— å¯¹åº”IDï¼Œè·³è¿‡è¯¥æ ‡æ³¨")
                continue
            
            points = shape['points']
            if len(points) < 2:
                print(f"âš ï¸ {json_path} ä¸­ {original_cn_label} æ ‡æ³¨ç‚¹æ•°é‡ä¸è¶³ï¼Œè·³è¿‡è¯¥æ ‡æ³¨")
                continue
            
            x_coords = [p[0] for p in points]
            y_coords = [p[1] for p in points]
            xmin = min(x_coords)
            ymin = min(y_coords)
            xmax = max(x_coords)
            ymax = max(y_coords)
            
            if xmin >= xmax or ymin >= ymax:
                print(f"âš ï¸ {json_path} ä¸­ {original_cn_label} æ ‡æ³¨æ¡†æ— æ•ˆï¼Œè·³è¿‡è¯¥æ ‡æ³¨")
                continue
            
            x_center = (xmin + xmax) / 2 / img_w
            y_center = (ymin + ymax) / 2 / img_h
            width = (xmax - xmin) / img_w
            height = (ymax - ymin) / img_h
            
            if not (0 <= x_center <= 1 and 0 <= y_center <= 1 and 0 < width <= 1 and 0 < height <= 1):
                print(f"âš ï¸ {json_path} ä¸­ {original_cn_label} åæ ‡è¶…å‡ºèŒƒå›´ï¼Œè·³è¿‡è¯¥æ ‡æ³¨")
                continue
            
            txt_lines.append(f"{cid} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")
        
        txt_lines = list(set(txt_lines))
        
        with open(save_label_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(txt_lines))
        
        if not txt_lines:
            print(f"âš ï¸ {json_path} è½¬æ¢åæ— æœ‰æ•ˆæ ‡æ³¨ï¼Œç”Ÿæˆç©ºæ ‡ç­¾æ–‡ä»¶")
        
        return True
    except Exception as e:
        print(f"âŒ è½¬æ¢ {json_path} å¤±è´¥ï¼š{str(e)}")
        return False

# æ¸…ç©ºç›®å½•
def clear_dir(dir_path):
    if os.path.exists(dir_path):
        for file in os.listdir(dir_path):
            file_path = os.path.join(dir_path, file)
            if os.path.isfile(file_path):
                os.remove(file_path)
            elif os.path.isdir(file_path):
                shutil.rmtree(file_path)

# ä¸»å¤„ç†é€»è¾‘
def auto_process_dataset():
    config = load_total_config()
    
    # ä»…æ‰«ææŒ‡å®šçš„å•ä¸ªç›®å½•
    file_pairs = scan_target_dir(config)
    if not file_pairs:
        return False
    
    # åˆå§‹åŒ–è¾“å‡ºç›®å½•
    train_img_dir = os.path.join(config['train_path'], 'images')
    train_label_dir = os.path.join(config['train_path'], 'labels')
    val_img_dir = os.path.join(config['val_path'], 'images')
    val_label_dir = os.path.join(config['val_path'], 'labels')
    
    # åˆ›å»ºç›®å½•å¹¶æ¸…ç©ºåŸæœ‰å†…å®¹
    for dir_path in [train_img_dir, train_label_dir, val_img_dir, val_label_dir]:
        os.makedirs(dir_path, exist_ok=True)
        clear_dir(dir_path)
    
    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
    random.seed(config['random_seed'])
    random.shuffle(file_pairs)
    train_num = int(len(file_pairs) * config['train_ratio'])
    train_pairs = file_pairs[:train_num]
    val_pairs = file_pairs[train_num:]
    
    print(f"\nğŸ“Š æ•°æ®é›†åˆ’åˆ†ï¼šè®­ç»ƒé›† {len(train_pairs)} å¼ ï¼ŒéªŒè¯é›† {len(val_pairs)} å¼ ")
    
    # å¤„ç†è®­ç»ƒé›†
    print("\n=== å¤„ç†è®­ç»ƒé›† ===")
    train_success = 0
    for img_path, json_path in tqdm(train_pairs, desc="è®­ç»ƒé›†è½¬æ¢"):
        img_name = os.path.basename(img_path)
        dst_img_path = os.path.join(train_img_dir, img_name)
        shutil.copy(img_path, dst_img_path)
        
        label_name = os.path.splitext(img_name)[0] + '.txt'
        dst_label_path = os.path.join(train_label_dir, label_name)
        if json2yolo(img_path, json_path, dst_label_path, config):
            train_success += 1
    
    # å¤„ç†éªŒè¯é›†
    print("\n=== å¤„ç†éªŒè¯é›† ===")
    val_success = 0
    for img_path, json_path in tqdm(val_pairs, desc="éªŒè¯é›†è½¬æ¢"):
        img_name = os.path.basename(img_path)
        dst_img_path = os.path.join(val_img_dir, img_name)
        shutil.copy(img_path, dst_img_path)
        
        label_name = os.path.splitext(img_name)[0] + '.txt'
        dst_label_path = os.path.join(val_label_dir, label_name)
        if json2yolo(img_path, json_path, dst_label_path, config):
            val_success += 1
    
    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    print(f"\nâœ… æ•°æ®é›†å¤„ç†å®Œæˆï¼š")
    print(f"  è®­ç»ƒé›†ï¼šæˆåŠŸè½¬æ¢ {train_success}/{len(train_pairs)} å¼ ")
    print(f"  éªŒè¯é›†ï¼šæˆåŠŸè½¬æ¢ {val_success}/{len(val_pairs)} å¼ ")
    print(f"  è®­ç»ƒé›†å›¾åƒï¼š{train_img_dir}")
    print(f"  è®­ç»ƒé›†æ ‡ç­¾ï¼š{train_label_dir}")
    print(f"  éªŒè¯é›†å›¾åƒï¼š{val_img_dir}")
    print(f"  éªŒè¯é›†æ ‡ç­¾ï¼š{val_label_dir}")
    
    # æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„train/valè·¯å¾„
    with open(config['config_path'], 'r+', encoding='utf-8') as f:
        total_config = yaml.safe_load(f)
        total_config['paths']['train'] = config['train_path']
        total_config['paths']['val'] = config['val_path']
        f.seek(0)
        yaml.dump(total_config, f, indent=2, allow_unicode=True)
        f.truncate()
    
    return True

if __name__ == "__main__":
    auto_process_dataset()