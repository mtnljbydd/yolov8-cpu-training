import os
import shutil
import yaml
import re
import sys
from tqdm import tqdm
# å½»åº•è§£å†³Windows/CPUä¸‹è¿›åº¦æ¡æ¢è¡Œé—®é¢˜çš„æ ¸å¿ƒé…ç½®
os.environ['PYTHONWARNINGS'] = 'ignore'
os.environ['TQDM_DISABLE'] = 'False'
os.environ['TQDM_POSITION'] = '0'
os.environ['TQDM_NCOLS'] = '100'
os.environ['TQDM_LINE_BREAKS'] = 'False'
os.environ['ULTRALYTICS_VERBOSE'] = 'True'
# å¼ºåˆ¶ä½¿ç”¨å…¼å®¹Windowsçš„è¿›åº¦æ¡æ¸²æŸ“å™¨
os.environ['TQDM_ENV'] = 'windows'

from ultralytics import YOLO
from ultralytics.utils import LOGGER

# é‡å†™tqdmç±»ï¼Œå¼ºåˆ¶å•è¡Œæ›´æ–°
class SingleLineTqdm(tqdm):
    def __init__(self, *args, **kwargs):
        kwargs['dynamic_ncols'] = True
        kwargs['position'] = 0
        kwargs['leave'] = False  # è¿›åº¦æ¡å®Œæˆåä¸ä¿ç•™ï¼Œä»…Epochç»“æŸåæ˜¾ç¤ºæ±‡æ€»
        kwargs['ncols'] = 100
        kwargs['bar_format'] = '{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'
        super().__init__(*args, **kwargs)
    
    def update(self, n=1):
        # å¼ºåˆ¶å•è¡Œåˆ·æ–°ï¼Œä¸æ¢è¡Œ
        super().update(n)
        self.refresh()

# æ›¿æ¢ultralyticså†…éƒ¨çš„tqdm
import ultralytics.utils.torch_utils
ultralytics.utils.torch_utils.tqdm = SingleLineTqdm
import ultralytics.engine.trainer
ultralytics.engine.trainer.tqdm = SingleLineTqdm

# è°ƒæ•´æ—¥å¿—çº§åˆ«ï¼Œä¿ç•™æ ¸å¿ƒä¿¡æ¯ï¼ˆä»…ä¿ç•™åˆæ³•é…ç½®ï¼‰
LOGGER.setLevel('INFO')

# åŠ è½½é…ç½®ï¼ˆé€‚é…target_scene_dirï¼‰
def load_total_config(config_path="./config/total_config.yaml"):
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # 1. è§£ææ¨¡å‹å‘½åé…ç½®
    model_naming = config['model_naming']
    custom_model_name = model_naming['model_name']
    custom_model_version = model_naming['model_version']
    final_exp_name = f"{custom_model_name}_{custom_model_version}"
    
    # 2. è§£æè·¯å¾„é…ç½®
    root_path = os.path.abspath(config['paths']['root_path'])
    target_scene_dir = os.path.abspath(config['paths']['target_scene_dir'])
    output_root = os.path.abspath(config['paths']['output_root'])
    train_path = os.path.abspath(config['paths'].get('train', os.path.join(output_root, 'train')))
    val_path = os.path.abspath(config['paths'].get('val', os.path.join(output_root, 'val')))
    
    # æ›¿æ¢å¯¼å‡ºè·¯å¾„å˜é‡
    export_save_path = config['paths']['export_save_path'].replace("{root_path}", root_path)
    export_save_path = export_save_path.replace("{model_name}", custom_model_name)
    export_save_path = export_save_path.replace("{model_version}", custom_model_version)
    export_save_path = os.path.abspath(export_save_path)
    
    # 3. è§£æç±»åˆ«ä¿¡æ¯
    class_dict = config['dataset']['class_dict']
    en2cid = {en_name: idx for idx, en_name in enumerate(class_dict.values())}
    sorted_en_names = [en for en, cid in sorted(en2cid.items(), key=lambda x: x[1])]
    
    return {
        "train_path": train_path,
        "val_path": val_path,
        "target_scene_dir": target_scene_dir,
        "nc": len(class_dict),
        "names": sorted_en_names,
        "custom_model_name": custom_model_name,
        "custom_model_version": custom_model_version,
        "final_exp_name": final_exp_name,
        "export_save_path": export_save_path,
        "model": config['training']['model'],
        "epochs": config['training']['epochs'],
        "batch_size": config['training']['batch'],
        "imgsz": config['training']['imgsz'],
        "device": config['training']['device'],
        "patience": config['training']['patience'],
        "save_period": config['training']['save_period'],
        "lr0": config['training']['learning_rate'],
        "weight_decay": config['training']['weight_decay'],
        "momentum": config['training']['momentum'],
        "warmup_epochs": config['training']['warmup_epochs'],
        "project": config['training']['project'],
        "exist_ok": config['training']['exist_ok'],
        "conf": config['validation']['conf'],
        "iou": config['validation']['iou'],
        "save_json": config['validation']['save_json'],
        "plots": config['validation']['plots'],
        "delete_temp": config['dataset']['delete_temp_files'],
        "output_root": output_root,
        "config_path": config_path
    }

# ç”ŸæˆYOLOæ‰€éœ€çš„ä¸´æ—¶data.yaml
def generate_yolo_data_yaml(config):
    temp_data = {
        "train": config['train_path'],
        "val": config['val_path'],
        "nc": config['nc'],
        "names": config['names']
    }
    
    temp_data_path = "./config/temp_yolo_data.yaml"
    os.makedirs(os.path.dirname(temp_data_path), exist_ok=True)
    with open(temp_data_path, 'w', encoding='utf-8') as f:
        yaml.dump(temp_data, f, indent=2, allow_unicode=True)
    
    return temp_data_path

# é‡å‘½åè®­ç»ƒåçš„æ¨¡å‹æ–‡ä»¶
def rename_trained_models(config):
    original_exp_dir = os.path.join(config['project'], "temp")
    final_exp_dir = os.path.join(config['project'], config['final_exp_name'])
    
    if os.path.exists(original_exp_dir) and not os.path.exists(final_exp_dir):
        os.rename(original_exp_dir, final_exp_dir)
        print(f"âœ… å®éªŒç›®å½•å·²é‡å‘½åï¼š{original_exp_dir} â†’ {final_exp_dir}")
    
    weights_dir = os.path.join(final_exp_dir, "weights")
    if os.path.exists(weights_dir):
        for file_name in os.listdir(weights_dir):
            if file_name in ["best.pt", "last.pt"]:
                new_file_name = f"{config['custom_model_name']}_{config['custom_model_version']}_{file_name}"
                old_path = os.path.join(weights_dir, file_name)
                new_path = os.path.join(weights_dir, new_file_name)
                
                if not os.path.exists(new_path):
                    os.rename(old_path, new_path)
                    print(f"âœ… æ¨¡å‹æ–‡ä»¶å·²é‡å‘½åï¼š{old_path} â†’ {new_path}")
    
    os.makedirs(config['export_save_path'], exist_ok=True)
    print(f"âœ… æ¨¡å‹å¯¼å‡ºç›®å½•å·²åˆ›å»ºï¼š{config['export_save_path']}")
    
    return final_exp_dir

# ä¸€é”®è®­ç»ƒYOLOv8
def train_yolov8():
    config = load_total_config()
    
    # ç”Ÿæˆä¸´æ—¶data.yaml
    temp_data_path = generate_yolo_data_yaml(config)
    print(f"âœ… ç”Ÿæˆä¸´æ—¶data.yamlï¼š{temp_data_path}")
    
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    model = YOLO(config['model'])
    print(f"âœ… åŠ è½½æ¨¡å‹ï¼š{config['model']}")
    print(f"âœ… è®­ç»ƒè®¾å¤‡ï¼š{config['device']}")
    print(f"âœ… è®­ç»ƒè½®æ•°ï¼š{config['epochs']}")
    print(f"âœ… æ‰¹æ¬¡å¤§å°ï¼š{config['batch_size']}")
    print(f"âœ… ç±»åˆ«æ•°é‡ï¼š{config['nc']}")
    print(f"âœ… è®­ç»ƒæ•°æ®æ¥æºï¼š{config['target_scene_dir']}")
    
    # å¼€å§‹è®­ç»ƒï¼ˆæ ¸å¿ƒï¼šè§£å†³è¿›åº¦æ¡æ¢è¡Œé—®é¢˜ï¼‰
    print("\n=== å¼€å§‹YOLOv8è®­ç»ƒ ===")
    results = model.train(
        data=temp_data_path,
        epochs=config['epochs'],
        batch=config['batch_size'],
        imgsz=config['imgsz'],
        device=config['device'],
        patience=config['patience'],
        save=True,
        save_period=config['save_period'],
        lr0=config['lr0'],
        weight_decay=config['weight_decay'],
        momentum=config['momentum'],
        warmup_epochs=config['warmup_epochs'],
        val=True,
        cache='disk',  # æ”¹ç”¨diskç¼“å­˜ï¼Œæ¶ˆé™¤RAMç¼“å­˜è­¦å‘Š
        verbose=True,
        project=config['project'],
        name="temp",
        exist_ok=config['exist_ok'],
        plots=config['plots'],
        save_json=config['save_json'],
        workers=0,  # CPUè®­ç»ƒå¼ºåˆ¶workers=0ï¼Œé¿å…å¤šçº¿ç¨‹è¿›åº¦æ¡é”™ä¹±
        single_cls=False
    )
    
    # é‡å‘½åæ¨¡å‹å’Œå®éªŒç›®å½•
    final_exp_dir = rename_trained_models(config)
    
    # éªŒè¯æœ€ä½³æ¨¡å‹
    print("\n=== éªŒè¯æœ€ä½³æ¨¡å‹ ===")
    best_model_name = f"{config['custom_model_name']}_{config['custom_model_version']}_best.pt"
    best_model_path = os.path.join(final_exp_dir, "weights", best_model_name)
    
    if not os.path.exists(best_model_path):
        best_model_path = os.path.join(final_exp_dir, "weights", "best.pt")
        if not os.path.exists(best_model_path):
            print(f"âŒ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹ï¼š{best_model_path}")
            return
    
    best_model = YOLO(best_model_path)
    val_results = best_model.val(
        data=temp_data_path,
        conf=config['conf'],
        iou=config['iou'],
        save_json=config['save_json'],
        plots=config['plots'],
        verbose=False
    )
    
    # è¾“å‡ºæ ¸å¿ƒç»“æœ
    print(f"\nğŸ‰ è®­ç»ƒ+éªŒè¯å®Œæˆï¼")
    print(f"ğŸ“ å®éªŒç›®å½•ï¼š{final_exp_dir}")
    print(f"ğŸ“Œ æœ€ä½³æ¨¡å‹è·¯å¾„ï¼š{best_model_path}")
    print(f"ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡ï¼š")
    print(f"   - éªŒè¯é›†mAP@0.5ï¼š{val_results.box.map50:.4f}ï¼ˆè¶Šæ¥è¿‘1è¶Šå¥½ï¼‰")
    print(f"   - éªŒè¯é›†mAP@0.5:0.95ï¼š{val_results.box.map:.4f}")
    try:
        print(f"   - æœ€ç»ˆbox_lossï¼š{results.results_dict['train/box_loss']:.4f}ï¼ˆè¶Šæ¥è¿‘0è¶Šå¥½ï¼‰")
        print(f"   - æœ€ç»ˆcls_lossï¼š{results.results_dict['train/cls_loss']:.4f}ï¼ˆè¶Šæ¥è¿‘0è¶Šå¥½ï¼‰")
    except KeyError:
        print(f"   - æœ€ç»ˆè®­ç»ƒæŸå¤±ï¼šå‚è€ƒ runs/detect/{config['final_exp_name']}/results.csv")
    print(f"ğŸ“¤ æ¨¡å‹å¯¼å‡ºç›®å½•ï¼š{config['export_save_path']}")
    
    # å¯é€‰åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    if config['delete_temp']:
        if os.path.exists(config['output_root']):
            shutil.rmtree(config['output_root'])
        if os.path.exists(temp_data_path):
            os.remove(temp_data_path)
        print(f"âœ… å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶")

if __name__ == "__main__":
    train_yolov8()